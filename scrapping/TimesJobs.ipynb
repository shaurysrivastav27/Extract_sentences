{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"TimesJobs_v3.0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzwF78GrZ5XD","executionInfo":{"status":"ok","timestamp":1630820058867,"user_tz":-330,"elapsed":928,"user":{"displayName":"Shaury Srivastava","photoUrl":"","userId":"17221522711714923321"}},"outputId":"3b2e1bb7-deaa-40ae-f247-8dad35bba86d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"PzwF78GrZ5XD","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3vfGKeOGZ5XH","executionInfo":{"status":"ok","timestamp":1630820087120,"user_tz":-330,"elapsed":27530,"user":{"displayName":"Shaury Srivastava","photoUrl":"","userId":"17221522711714923321"}},"outputId":"f98deaae-d5ad-4116-df55-b1613e7988e8"},"source":["!apt install chromium-chromedriver"],"id":"3vfGKeOGZ5XH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n","Suggested packages:\n","  webaccounts-chromium-extension unity-chromium-extension\n","The following NEW packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-chromedriver\n","  chromium-codecs-ffmpeg-extra\n","0 upgraded, 4 newly installed, 0 to remove and 40 not upgraded.\n","Need to get 91.8 MB of archives.\n","After this operation, 315 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 92.0.4515.159-0ubuntu0.18.04.1 [1,124 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 92.0.4515.159-0ubuntu0.18.04.1 [81.7 MB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 92.0.4515.159-0ubuntu0.18.04.1 [4,026 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 92.0.4515.159-0ubuntu0.18.04.1 [4,902 kB]\n","Fetched 91.8 MB in 6s (16.1 MB/s)\n","Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n","(Reading database ... 148492 files and directories currently installed.)\n","Preparing to unpack .../chromium-codecs-ffmpeg-extra_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-codecs-ffmpeg-extra (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser.\n","Preparing to unpack .../chromium-browser_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-browser (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser-l10n.\n","Preparing to unpack .../chromium-browser-l10n_92.0.4515.159-0ubuntu0.18.04.1_all.deb ...\n","Unpacking chromium-browser-l10n (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Setting up chromium-codecs-ffmpeg-extra (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser (92.0.4515.159-0ubuntu0.18.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser-l10n (92.0.4515.159-0ubuntu0.18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tJ9npHdEZ5XI","executionInfo":{"status":"ok","timestamp":1630820096013,"user_tz":-330,"elapsed":8912,"user":{"displayName":"Shaury Srivastava","photoUrl":"","userId":"17221522711714923321"}},"outputId":"eb373a5b-b83a-443e-ac86-61da1ae66af1"},"source":["# For Selenium n Google Colab\n","!pip install selenium\n","!apt-get update \n","!pip install webdriver-manager"],"id":"tJ9npHdEZ5XI","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n","\u001b[?25l\r\u001b[K     |▍                               | 10 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 36.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 71 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 92 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 102 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 122 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 133 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 143 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 153 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 163 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 174 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 184 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 194 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 204 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 215 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 225 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 235 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 245 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 256 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 266 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 276 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 286 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 296 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 307 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 317 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 327 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 337 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 348 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 358 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 368 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 378 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 389 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 399 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 409 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 419 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 430 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 440 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 450 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 460 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 471 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 481 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 491 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 501 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 512 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 522 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 532 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 542 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 552 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 563 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 573 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 583 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 593 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 604 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 614 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 624 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 634 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 645 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 655 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 665 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 675 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 686 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 696 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 706 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 716 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 727 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 737 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 747 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 757 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 768 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 778 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 788 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 798 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 808 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 819 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 829 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 839 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 849 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 860 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 870 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 880 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 890 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 901 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 904 kB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n","Installing collected packages: selenium\n","Successfully installed selenium-3.141.0\n","Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [700 kB]\n","Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Fetched 957 kB in 2s (484 kB/s)\n","Reading package lists... Done\n","Collecting webdriver-manager\n","  Downloading webdriver_manager-3.4.2-py2.py3-none-any.whl (16 kB)\n","Collecting configparser\n","  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n","Collecting crayons\n","  Downloading crayons-0.4.0-py2.py3-none-any.whl (4.6 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (2.23.0)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (3.0.4)\n","Installing collected packages: colorama, crayons, configparser, webdriver-manager\n","Successfully installed colorama-0.4.4 configparser-5.0.2 crayons-0.4.0 webdriver-manager-3.4.2\n"]}]},{"cell_type":"code","metadata":{"id":"d6TCtIH7Z5XI"},"source":["from webdriver_manager.firefox import DriverManager\n","from selenium.common.exceptions import ElementClickInterceptedException\n","from selenium.common.exceptions import NoSuchElementException"],"id":"d6TCtIH7Z5XI","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xu2osfi1YoSo","executionInfo":{"status":"ok","timestamp":1630820098044,"user_tz":-330,"elapsed":832,"user":{"displayName":"Shaury Srivastava","photoUrl":"","userId":"17221522711714923321"}},"outputId":"61a06db8-b518-4205-88b2-acf97a41b01d"},"source":["!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin"],"id":"Xu2osfi1YoSo","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","chromium-chromedriver is already the newest version (92.0.4515.159-0ubuntu0.18.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"]}]},{"cell_type":"code","metadata":{"id":"psQTjvJMYe0-"},"source":["import sys\n","sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"],"id":"psQTjvJMYe0-","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-u9p20I8Z5XJ","executionInfo":{"status":"ok","timestamp":1630820099236,"user_tz":-330,"elapsed":1201,"user":{"displayName":"Shaury Srivastava","photoUrl":"","userId":"17221522711714923321"}},"outputId":"21d46372-da32-4933-ef49-28b98f525d6a"},"source":["from selenium import webdriver\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","driver =webdriver.Chrome('chromedriver',chrome_options=chrome_options)"],"id":"-u9p20I8Z5XJ","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n","  \n"]}]},{"cell_type":"code","metadata":{"id":"248179c0"},"source":["import pandas as pd\n","import numpy as np\n","import time\n","import os\n","import io\n","import numpy as np\n","import requests\n","from datetime import datetime \n","import csv\n","import re\n","from bs4 import BeautifulSoup\n","from selenium import webdriver\n","from selenium.webdriver.firefox.options import Options"],"id":"248179c0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QEzzxyP-B-O-","executionInfo":{"status":"ok","timestamp":1630820101278,"user_tz":-330,"elapsed":2045,"user":{"displayName":"Shaury Srivastava","photoUrl":"","userId":"17221522711714923321"}},"outputId":"a16ab594-90e6-4033-f48b-5e5a53f268ec"},"source":["!apt install chromium-chromedriver"],"id":"QEzzxyP-B-O-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","chromium-chromedriver is already the newest version (92.0.4515.159-0ubuntu0.18.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ty6GRepiBhc5","executionInfo":{"status":"ok","timestamp":1630820109000,"user_tz":-330,"elapsed":7728,"user":{"displayName":"Shaury Srivastava","photoUrl":"","userId":"17221522711714923321"}},"outputId":"bb943d39-ec77-4434-8f89-30cbd41db179"},"source":["# For Selenium n Google Colab\n","!pip install selenium\n","!apt-get update \n","!pip install webdriver-manager"],"id":"ty6GRepiBhc5","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n","Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Reading package lists... Done\n","Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.7/dist-packages (3.4.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (2.23.0)\n","Requirement already satisfied: crayons in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (0.4.0)\n","Requirement already satisfied: configparser in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (5.0.2)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from crayons->webdriver-manager) (0.4.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (3.0.4)\n"]}]},{"cell_type":"code","metadata":{"id":"9a74b90a"},"source":["from webdriver_manager.firefox import DriverManager\n","from selenium.common.exceptions import ElementClickInterceptedException\n","from selenium.common.exceptions import NoSuchElementException"],"id":"9a74b90a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwmrdzQlBnan","executionInfo":{"status":"ok","timestamp":1630820109745,"user_tz":-330,"elapsed":759,"user":{"displayName":"Shaury Srivastava","photoUrl":"","userId":"17221522711714923321"}},"outputId":"c08b2b69-43e0-4fd7-98c8-86b2923381dd"},"source":["from selenium import webdriver\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","driver =webdriver.Chrome('chromedriver',chrome_options=chrome_options)"],"id":"OwmrdzQlBnan","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n","  \n"]}]},{"cell_type":"markdown","metadata":{"id":"f2fcebb1"},"source":["## filling the NaN value with the word \"missing\""],"id":"f2fcebb1"},{"cell_type":"code","metadata":{"id":"ef5bbc92"},"source":["dfs = pd.read_excel('/content/drive/MyDrive/Semantic Titles.xlsx', sheet_name='Sheet1')\n","dfs.fillna('missing',inplace=True) "],"id":"ef5bbc92","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37f15a47","executionInfo":{"status":"ok","timestamp":1630820110987,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shaury Srivastava","photoUrl":"","userId":"17221522711714923321"}},"outputId":"20eda189-9861-47d5-e53a-6925a178cb7e"},"source":["dfs['scrapenum'] = 0\n","for i in range(0,len(dfs)):\n","    #print('\\n')\n","    if((i>0) and (dfs['scrapenum'][i-1]==0) and (cnt>0)):\n","        dfs['scrapenum'][i-1]=cnt-1\n","    cnt = 0 \n","    for j in dfs.columns:\n","        #print(df[j][i])\n","        if(dfs[j][i]=='missing'):\n","            dfs['scrapenum'][i] = cnt-1\n","            break\n","        cnt = cnt+1"],"id":"37f15a47","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n"]}]},{"cell_type":"code","metadata":{"id":"debc0e73"},"source":["url = 'https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords={job}&txtLocation='"],"id":"debc0e73","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4d00c7b"},"source":["url1 = 'https://www.timesjobs.com/candidate/job-search.html?from=submit&actualTxtKeywords={job}&searchBy=0&rdoOperator=OR&searchType=personalizedSearch&luceneResultSize=25&postWeek=60&txtKeywords={job}&pDate=I&sequence={num}&startPage=1'"],"id":"c4d00c7b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"98fca22a"},"source":["def get_url(position):\n","    x = position.lower().split()\n","    link = url.format(job=\"+\".join(x))\n","    return link\n","\n","def get_url1(position,num):\n","    x = position.lower().split()\n","    link = url1.format(job=\"%20\".join(x),num=num)\n","    return link"],"id":"98fca22a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RnpINV3gX6q9"},"source":["## Please change the paths for the education.csv"],"id":"RnpINV3gX6q9"},{"cell_type":"code","metadata":{"id":"gDnbCG4j9KEf"},"source":["educ = []\n","educate = pd.read_csv('/content/drive/MyDrive/data/EducationWords.csv') \n","for i in educate['Education']:\n","    educ.append(\"\\b\"+i+\"\\b\")"],"id":"gDnbCG4j9KEf","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b9GUJKvjxYkN"},"source":["certis = {}\n","for i in dfs['Job Title']:\n","  certis[i] = \"\""],"id":"b9GUJKvjxYkN","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9c1bzk6bpez1"},"source":["cert = pd.read_csv('/content/drive/MyDrive/data/certificates.csv') \n","for i in range(0,len(cert)):\n","  certis[cert['Job'][i].rstrip().lstrip()] = cert['Certificates'][i]"],"id":"9c1bzk6bpez1","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sq25RjhcylEt"},"source":["### functions "],"id":"Sq25RjhcylEt"},{"cell_type":"code","metadata":{"id":"PwzuxXgOygoJ"},"source":["def res(x):\n","  for k in ['responsibility','funcion','activities','activity','responsibilities','responsible']:\n","    if(re.search(k,x)):\n","      return x[re.search(k,x.lower()).span()[0]:len(x)]\n","  return 'None'\n","\n","def repl(x):\n","  return x.replace(\"\\t\",\"\").replace(\"\\n\",\"\").rstrip().lstrip().replace(\"  \",\" \")\n","df['skills'] = df['skills'].map(repl)\n","df['description'] = df['description'].map(repl)\n","\n","def edu(x):\n","  try:\n","    start = re.search('Qualification:',x).span()[0]\n","    end = re.search(\"Employment Type:\",x).span()[0]\n","    return x[start:end-1]\n","  except:\n","    return 'None'"],"id":"PwzuxXgOygoJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cd4009ba"},"source":["### the main loop for scrapping"],"id":"cd4009ba"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d635ce65","executionInfo":{"status":"ok","timestamp":1630829599712,"user_tz":-330,"elapsed":2219,"user":{"displayName":"Shaury Srivastava","photoUrl":"","userId":"17221522711714923321"}},"outputId":"ab451438-07d8-47fc-b167-86a131cf6051"},"source":["df = pd.DataFrame()\n","fincnt = 1\n","for i in range(0,len(dfs)):\n","    namelist,desc,skill,experience,links,salary,location,semantics,certifications=[],[],[],[],[],[],[],[],[],[]\n","    counter=0\n","    if(dfs['scrapenum'][i]<=1):\n","        counter = 50\n","    else:\n","        mul = 50//dfs['scrapenum'][i]\n","        if(mul*dfs['scrapenum'][i]<50):\n","          counter = (50//dfs['scrapenum'][i]) + 1\n","    stringname = dfs['Job Title'][i]\n","    if(counter<25):\n","      print(\"----------------# \",dfs['Job Title'][i],\"Page (1)------------\")\n","    for j in dfs.drop(['Semantic Words','scrapenum'],axis=1).columns:\n","        if(dfs[j][i]=='missing'):\n","          break\n","        else:\n","            time.sleep(3)\n","            if(counter<25):\n","                htmlfile = requests.get(get_url(dfs[j][i]))    ## taking the input from the excel file \n","                soup = BeautifulSoup(htmlfile.content,'html5lib')\n","                joblist = soup.find_all('span','srp-skills')\n","                for span in joblist[0:counter]:   ## extracting the skills columns from the webpage\n","                    semantics.append(dfs[j][i])\n","                    skill.append(span.text)\n","\n","                for ul in soup.find_all('ul',{\"class\":\"top-jd-dtl\"})[0:counter]:\n","                  if(len(ul.find_all('li'))==3):\n","                    experience.append(ul.find_all('li')[0].text.replace(\"card_travel\",\"\"))\n","                    salary.append(ul.find_all('li')[1].text)\n","                    location.append(ul.find_all('li')[2].text.replace(\"location_on\",\"\"))\n","                  else:\n","                      experience.append(ul.find_all('li')[0].text.replace(\"card_travel\",\"\"))\n","                      salary.append('Not disclosed')\n","                      location.append(ul.find_all('li')[1].text.replace(\"location_on\",\"\"))\n","                if(len(joblist)<1):\n","                        htmlfile = requests.get(get_url1(dfs[j][i],1))    ## taking the input from the excel file \n","                        soup = BeautifulSoup(htmlfile.content,'html5lib')\n","                \n","                    \n","                for div in soup.find('ul',{\"class\":\"new-joblist\"}).find_all('li',{\"class\":\"clearfix job-bx wht-shd-bx\"})[0:counter]:\n","                    links.append(div.find('a',href=True)['href'])\n","                    soup1 = BeautifulSoup(requests.get(links[len(links)-1]).content,'html5lib')\n","                    t = soup1.find('div','jd-sec')\n","                    if(t):\n","                      descript = t.text\n","                    else:\n","                      descript = 'None'\n","                    desc.append(descript)\n","                    certitext = \"\"\n","                    for cer in certis[dfs['Job Title'][i]].split(\",\"):\n","                      if(re.search(cer.lstrip().rstrip(),descript)):\n","                        certitext = cer+ \" \"+certitext \n","                    if(certitext==''):\n","                      certitext= 'None'\n","                    certifications.append(certitext)\n","                    edi = \"\"\n","                    for ed in educ:\n","                      if(re.search(ed,descript.lower().replace(\"/\",\" \").replace(\".\",\"\"))):\n","                        edi = edi+ \" \"+ed\n","                    education.append(edi)\n","\n","                localcnt = 0\n","                for ul1 in soup.find_all('ul','top-jd-dtl clearfix'):   ## extracting the years of experience \n","                    if(localcnt==counter):\n","                        break\n","                    for a in ul1.find_all('a',href=True):\n","                      links.append(a['href'])\n","                      print(a['href'])\n","                joblist = soup.find_all('h3',{\"class\":\"joblist-comp-name\"})\n","                for name in joblist[0:counter]:\n","                    namelist.append(name.text.split(\"\\n\")[1])\n","            else:\n","                for indices in range(1,3):\n","                    print(\"----------------# \",dfs['Job Title'][i],\"Page (\",indices,\")------------\")\n","                    htmlfile = requests.get(get_url(dfs[j][i]))    \n","                    soup = BeautifulSoup(htmlfile.content,'html5lib')\n","                    if(indices==2):\n","                        htmlfile = requests.get(get_url1(dfs[j][i],indices))   \n","                        soup = BeautifulSoup(htmlfile.content,'html5lib')\n","                    joblist = soup.find_all('ul','new-joblist') \n","                    for ul in soup.find_all('ul',{\"class\":\"top-jd-dtl\"}):\n","                      if(len(ul.find_all('li'))==3):\n","                          experience.append(ul.find_all('li')[0].text.replace(\"card_travel\",\"\"))\n","                          salary.append(ul.find_all('li')[1].text)\n","                          location.append(ul.find_all('li')[2].text.replace('location_on',\"\"))\n","                      else:\n","                          experience.append(ul.find_all('li')[0].text.replace(\"card_travel\",\"\"))\n","                          salary.append('Not disclosed')\n","                          location.append(ul.find_all('li')[1].text.replace('location_on',\"\"))\n","                    for div in soup.find('ul',{\"class\":\"new-joblist\"}).find_all('li',{\"class\":\"clearfix job-bx wht-shd-bx\"}):\n","                          links.append(div.find('a',href=True)['href'])\n","                          soup1 = BeautifulSoup(requests.get(links[len(links)-1]).content,'html5lib')\n","                          t = soup1.find('div','jd-sec')\n","                          if(t):\n","                            descript = t.text\n","                          else:\n","                            descript = 'None'\n","                          desc.append(descript)\n","                          certitext = \"\"\n","                          for cer in certis[dfs['Job Title'][i]].split(\",\"):\n","                            if(re.search(cer.lstrip().rstrip(),descript)):\n","                              certitext = cer+ \" \"+certitext \n","                          if(certitext==''):\n","                            certitext= 'None'\n","                          certifications.append(certitext)\n","                          edi = \"\"\n","                          for ed in educ:\n","                            if(re.search(ed,ed,descript.lower().replace(\"/\",\" \").replace(\".\",\"\")))):\n","                              edi = edi+ \" \"+ed\n","                          education.append(edi)  \n","                    for ul1 in soup.find_all('ul','top-jd-dtl clearfix'):   ## extracting the years of experience \n","                          for a in ul1.find_all('a',href=True):\n","                            links.append(a['href'])\n","                            print(a['href'])\n","                    for ul in joblist:\n","                          for span in ul.find_all('span','srp-skills'):   ## extracting the skills columns from the webpage\n","                              skill.append(span.text)\n","                    joblist = soup.find_all('h3',{\"class\":\"joblist-comp-name\"})\n","                    for name in joblist:\n","                          semantics.append(dfs[j][i])\n","                          namelist.append(name.text.split(\"\\n\")[1]) \n","    #print(len(namelist),len(skill),len(experience),len(location),len(salary),len(education),len(links),len(desc))\n","    classjob = []\n","    for _ in range(0,len(namelist)):\n","      classjob.append(stringname)         \n","    dftemp = pd.DataFrame({\"Job Title\":semantics,\n","                            \"Searched Job Title\":classjob,\n","                           \"Company Name\":namelist,\n","                           \"skills\":skill,\n","                           \"description\":desc,\n","                           \"location\":location,\n","                           \"Experience\":experience,\n","                           \"certifications\":certifications,\n","                           \"salary\":salary,\n","                           \"links\":links})\n","    df = pd.concat([df,dftemp])\n","    #dftemp.to_csv('/content/drive/MyDrive/data/times/{}.csv'.format(dfs['Job Title'][i]))\n","df.reset_index(drop=True)\n","df['skills'] = df['skills'].map(repl)\n","df['description'] = df['description'].map(repl)\n","df['education'] = df['description'].map(edu)\n","df['responsibilty/activity'] = df['description'].map(res)\n","df.to_csv('/content/drive/MyDrive/data/{}.csv'.format('timesjobs'))"],"id":"d635ce65","execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["----------------#  Information Technology Analyst Page (1)------------\n","----------------#  Information Technology Application Specialist Page ( 1 )------------\n","----------------#  Information Technology Application Specialist Page ( 2 )------------\n","----------------#  Information Technology Assistant Page (1)------------\n","----------------#  Information Technology Consultant Page (1)------------\n","----------------#  Information Technology Engineer Page (1)------------\n","----------------#  Information Technology Manager Page (1)------------\n","----------------#  Information Technology Project Manager Page (1)------------\n","----------------#  Information Technology Recruiter Page (1)------------\n","----------------#  Information Technology Services Specialist Page (1)------------\n","----------------#  Information Technology Specialist Page (1)------------\n","----------------#  Information Technology Supervisor Page (1)------------\n","----------------#  Information Technology Support Specialist Page ( 1 )------------\n","----------------#  Information Technology Support Specialist Page ( 2 )------------\n","----------------#  Information Technology Technician Page (1)------------\n","----------------#  Inside Sales Specialist Page ( 1 )------------\n","----------------#  Inside Sales Specialist Page ( 2 )------------\n","----------------#  Internal Audit Manager Page (1)------------\n","----------------#  Internal Auditor Page (1)------------\n","----------------#  Internet of Things Consultant Page ( 1 )------------\n","----------------#  Internet of Things Consultant Page ( 2 )------------\n","----------------#  Internet of Things Engineer Page (1)------------\n","----------------#  Internet of Things Intern Page ( 1 )------------\n","----------------#  Internet of Things Intern Page ( 2 )------------\n","----------------#  Internet of Things Manager Page ( 1 )------------\n","----------------#  Internet of Things Manager Page ( 2 )------------\n","----------------#  Internet of Things Specialist Page ( 1 )------------\n","----------------#  Internet of Things Specialist Page ( 2 )------------\n","----------------#  Investment Banking Analyst Page (1)------------\n","----------------#  Investment Banking Associate Page ( 1 )------------\n","----------------#  Investment Banking Associate Page ( 2 )------------\n","----------------#  Investment Banking Intern Page ( 1 )------------\n","----------------#  Investment Banking Intern Page ( 2 )------------\n","----------------#  Investment Banking Specialist Page ( 1 )------------\n","----------------#  Investment Banking Specialist Page ( 2 )------------\n","----------------#  Investment Specialist Page (1)------------\n","----------------#  iOS Developer Page ( 1 )------------\n","----------------#  iOS Developer Page ( 2 )------------\n","----------------#  Java Analyst Page ( 1 )------------\n","----------------#  Java Analyst Page ( 2 )------------\n","----------------#  Java Application Developer Page ( 1 )------------\n","----------------#  Java Application Developer Page ( 2 )------------\n","----------------#  Java Architect Page (1)------------\n","----------------#  Java Consultant Page (1)------------\n","----------------#  Java Developer Page (1)------------\n","----------------#  Java Development Environment Consultant Page (1)------------\n","----------------#  Java Software Engineer Page (1)------------\n","----------------#  Java Specialist Page (1)------------\n"]}]},{"cell_type":"code","metadata":{"id":"_7bmcVOo3Z5V"},"source":[""],"id":"_7bmcVOo3Z5V","execution_count":null,"outputs":[]}]}