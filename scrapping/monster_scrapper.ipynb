{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, StaleElementReferenceException,ElementNotInteractableException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "unclean_df = pd.DataFrame()\n",
    "path = 'C:\\\\Users\\\\Dell\\\\OneDrive\\\\DataR Labs\\\\Resume_Parser\\\\chromedriver'\n",
    "titles = pd.read_excel('C:\\\\Users\\\\Dell\\\\OneDrive\\\\DataR Labs\\\\Resume_Parser\\\\titles.xlsx')\n",
    "#titles = titles[245:276]\n",
    "titles = titles[397:]\n",
    "\n",
    "no_of_jobs = 50\n",
    "verb = False\n",
    "sleept = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, num_jobs,path,slp_time):\n",
    "    \n",
    "    #timer\n",
    "    startTime = time.time()\n",
    "    \n",
    "    #driver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('headless')\n",
    "    driver = webdriver.Chrome(executable_path=path, options=options)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "    \n",
    "    #counter and flags\n",
    "    jobs = []\n",
    "    num = 0\n",
    "    i=1\n",
    "    \n",
    "    #url\n",
    "    url ='https://www.monster.com/jobs/search?q='+ keyword +'&where=&geo=%27%27'\n",
    "    jobs = []\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except WebDriverException:\n",
    "        print('Page Down')\n",
    "        return pd.DataFrame(jobs)\n",
    "    \n",
    "    print(\"Extracting: \"+keyword)\n",
    "    \n",
    "    #wait\n",
    "    time.sleep(slp_time)\n",
    "    \n",
    "    #get parent id's\n",
    "    listButtonsCount = driver.find_elements_by_class_name('results-card')\n",
    "    job_buttons = driver.find_elements_by_xpath('//*[@class=\"title-company-location\"]/a')\n",
    "    \n",
    "    #print(job_buttons.text)\n",
    "    \n",
    "    #links = driver.find_elements_by_class_name('title-company-location')\n",
    "    #for link in links:\n",
    "     #   print(link.text)\n",
    "    for job_button in job_buttons:\n",
    "        \n",
    "        if not(num<5):\n",
    "            #print(num)\n",
    "            #print(num_jobs)\n",
    "            executionTime = (time.time() - startTime)\n",
    "            print('Execution time in seconds: ' + str(executionTime))\n",
    "            return pd.DataFrame(jobs)\n",
    "            \n",
    "        #print(job_button.text)\n",
    "        try:\n",
    "            job_button.click()\n",
    "        except (StaleElementReferenceException,ElementNotInteractableException) as e:\n",
    "            pass\n",
    "        \n",
    "        #time.sleep(3)\n",
    "        #print(driver.find_element_by_xpath('//div[contains(@class, \"results-card selected\")]/a'))\n",
    "        \n",
    "        #company name\n",
    "        try:\n",
    "            company_name = driver.find_element_by_xpath('//*[@id=\"app\"]/div[2]/div/div[2]/div[2]/div[2]/div/div/div/div[1]/div/div[2]/div[1]').text\n",
    "        except (NoSuchElementException,StaleElementReferenceException) as e:\n",
    "            company_name = '-1'\n",
    "        \n",
    "        #location\n",
    "        try:\n",
    "            location = driver.find_element_by_xpath('//*[@id=\"app\"]/div[2]/div/div[2]/div[2]/div[2]/div/div/div/div[1]/div/div[2]/div[2]/div[1]').text\n",
    "        except (NoSuchElementException,StaleElementReferenceException) as e:\n",
    "            location = '-1'\n",
    "        \n",
    "        #job title\n",
    "        try:\n",
    "            job_title = driver.find_element_by_xpath('//*[@id=\"app\"]/div[2]/div/div[2]/div[2]/div[2]/div/div/div/div[1]/div/div[2]/h1').text\n",
    "        except (NoSuchElementException,StaleElementReferenceException) as e:\n",
    "            job_title = '-1'\n",
    "        \n",
    "        #job description\n",
    "        try:\n",
    "            job_description = driver.find_element_by_xpath(\"//div[contains(@class, 'jobdescriptioncomponent__SanitizedHtmlContainer-my61fv-2 gvwQGf')]\").text\n",
    "        except (NoSuchElementException,StaleElementReferenceException) as e:\n",
    "            job_description = '-1'\n",
    "        \n",
    "        #job function\n",
    "        try:\n",
    "            job_function = driver.find_element_by_xpath('//*[@id=\"app\"]/div[2]/div/div[2]/div[2]/div[2]/div/div/div/div[1]/div/div[2]/h1').text\n",
    "        except (NoSuchElementException,StaleElementReferenceException) as e:\n",
    "            job_function = '-1'\n",
    "            \n",
    "        try:\n",
    "            j = str(i)\n",
    "            link = driver.find_element_by_xpath('//*[@id=\"card-view-panel\"]/div/div[1]/div['+ j +']/div[1]/div[1]/div/div[1]/div[2]/a').get_attribute('href')\n",
    "            #print(driver.find_element_by_class_name(\"title-company-location\").get_attribute(\"href\"))\n",
    "            #print(driver.find_element_by_xpath('//div[contains(@class, \"results-card selected\")]/a').get_attribute('href'))\n",
    "            #print(driver.find_element_by_xpath(\"//div[@class='title-company-location']/a\").get_attribute(\"href\"))\n",
    "            i = i+1\n",
    "        except (NoSuchElementException,StaleElementReferenceException) as e:\n",
    "            link = '-1'\n",
    "        \n",
    "        num = num+1\n",
    "        jobs.append({\"Job Title\" : job_title,\n",
    "                     \"Searched Job Title\" : keyword,\n",
    "                     \"Company Name\" : company_name,\n",
    "                     \"Full Description\" : job_description,\n",
    "                     \"Location\" : location,\n",
    "                     \"URL\" : link})\n",
    "        #print(\"----- {0} {1} -----\".format(num,keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "titles['NJ'] = ''\n",
    "for rowIndex, row in titles.iterrows(): #iterate over rows\n",
    "    k=0\n",
    "    for columnIndex, value in row.items():\n",
    "        value = str(value)\n",
    "        if not (value=='NaN' or value == 'nan'):\n",
    "            k=k+1\n",
    "    titles['NJ'][rowIndex] = math.floor(40/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rowIndex, row in titles.iterrows(): #iterate over rows\n",
    "    k=0\n",
    "    for columnIndex, value in row.items():\n",
    "        value = str(value)\n",
    "        if not (value=='NaN' or value == 'nan'):\n",
    "            #print(titles['NJ'][rowIndex])\n",
    "            df1 = get_jobs(value, titles['NJ'][rowIndex],path,sleept) \n",
    "        df = df.append(df1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordninja\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "# Function to generate n-grams from sentences.\n",
    "def extract_ngrams(data):\n",
    "    l = []\n",
    "    for i in range(1,6):\n",
    "        n_grams = ngrams(nltk.word_tokenize(data), i)\n",
    "        l.append( [' '.join(grams) for grams in n_grams])\n",
    "    flat_ls = list(itertools.chain(*l))\n",
    "    return (flat_ls)\n",
    "\n",
    "\n",
    "def remove_accented_chars(x):\n",
    "    \"\"\"The function changes the accented characters into their equivalent normal form,\n",
    "    to do so, normalize function with 'NFKD' is used which replaces the compatibility characters into\n",
    "    theri euivalent\n",
    "    \n",
    "  param x(str): the sentence in which accented characters are to be detected and removes\n",
    "  return x(str): sentence with accented characters replaced by their equivalent\"\"\"\n",
    "    \n",
    "    x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess(df,d):\n",
    "    \"\"\"Preprocesses the given document by applying the following functionalities\n",
    "  lower: lowers all the characters for uniformity\n",
    "  remove special characters: using regex, removes all the punctuations etc\n",
    "  remove space: removes trailing spaces and extra spaces between words\n",
    "  remove accented characters: change accented characters to its normal equivalent\n",
    "  remove stop words\"\"\"\n",
    "  \n",
    "    df[d] = df[d].apply(lambda x: x.lower())\n",
    "    df[d] = df[d].apply(lambda x: re.sub('[^A-Z a-z 0-9-]+', '', x))\n",
    "    df[d] = df[d].apply(lambda x: \" \".join(x.split()))\n",
    "    df[d] = df[d].apply(lambda x: remove_accented_chars(x))\n",
    "    df[d] = df[d].apply(lambda x: \" \".join([t for t in x.split() if t not in STOP_WORDS]))\n",
    "\n",
    "\n",
    "def salary_extract(x):\n",
    "    #change to string\n",
    "    if x == -1:\n",
    "        return 'Missing Value'\n",
    "    return x.astype(str)    \n",
    "    \n",
    "def get_experience(x):\n",
    "    \"\"\"\n",
    "    param\n",
    "     -x : Textfield from where experience is to be extracted\n",
    "    return\n",
    "     -item : Returns year of experience if available, or returns -1 if not available \n",
    "    \"\"\"\n",
    "    \n",
    "    exp = re.findall('\\\\d+\\\\s+(?:months?|years?)',x)\n",
    "    if exp:\n",
    "        for item in exp:\n",
    "            return item\n",
    "    else:\n",
    "        return ('-1')    \n",
    "\n",
    "def get_language(x):\n",
    "\n",
    "    \"\"\"\n",
    "    Matched field with with language dictionary and returns languages if present in feild\n",
    "    \n",
    "    param\n",
    "     -x : Textfield from where language is to be extracted\n",
    "    return\n",
    "     -item : Returns language if available, or returns -1 if not available \n",
    "    \"\"\"\n",
    "    \n",
    "    language_dictionary = ['english',\n",
    "                           'french',\n",
    "                           'spanish',\n",
    "                           'chinese',\n",
    "                           'german',\n",
    "                           'mandarin',\n",
    "                           'japanese',\n",
    "                           'russian']\n",
    "    lang = ''\n",
    "    \n",
    "    for word in language_dictionary:\n",
    "        if word in x:\n",
    "            lang = lang + \"|\" + word\n",
    "    if lang == '':\n",
    "        return ('-1')\n",
    "    else:\n",
    "        return lang\n",
    "\n",
    "\n",
    "def split_(k):\n",
    "    l = wordninja.split(k)\n",
    "    x = ''\n",
    "    for word in l:\n",
    "        x = x+word+' '\n",
    "    return (x)\n",
    "\n",
    "def get_responsibility(x):\n",
    "    res = ['responsibilities',\n",
    "           'responsibility',\n",
    "           'function',\n",
    "           'activities',\n",
    "           'activity',\n",
    "           'responsible',\n",
    "           'role',\n",
    "           'roles',\n",
    "           'day',\n",
    "           'workday',\n",
    "           'day to day']\n",
    "    flag = False\n",
    "    #x = x.split()\n",
    "    #print(x)\n",
    "    \n",
    "    for word in res:\n",
    "        #print(word)\n",
    "        try:\n",
    "            pos = x.index(word)\n",
    "            flag = True\n",
    "            return (x[pos+len(word):pos+300])\n",
    "        except ValueError:\n",
    "            flag = False\n",
    "    return ('No Value')\n",
    "\n",
    "def get_skills(x):\n",
    "    res = ['sucessful candidates',\n",
    "           'skills',\n",
    "           'expectation',\n",
    "           'ideal candidate will have',\n",
    "           'ideal candidate will possess',\n",
    "           'skills you have',\n",
    "           'you possess',\n",
    "           'skill',\n",
    "           'requirement',\n",
    "           'you are an ideal candidate if',\n",
    "           'skills required']\n",
    "    flag = False\n",
    "    #x = x.split()\n",
    "    #print(x)\n",
    "    \n",
    "    for word in res:\n",
    "        #print(word)\n",
    "        try:\n",
    "            pos = x.index(word)\n",
    "            flag = True\n",
    "            return (x[pos+len(word):pos+300])\n",
    "        except ValueError:\n",
    "            flag = False\n",
    "    return ('No Value')\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "certis = {}\n",
    "for i in df['Job Title']:\n",
    "    certis[i] = \"\"\n",
    "\n",
    "cert = pd.read_csv('C:\\\\Users\\\\Dell\\\\OneDrive\\\\DataR Labs\\\\Resume_Parser\\\\certificates.csv') \n",
    "for i in range(0,len(cert)):\n",
    "    certis[cert['Job'][i].rstrip().lstrip()] = cert['Certificates'][i]\n",
    "\n",
    "\n",
    "certifications = []\n",
    "for ind in range(0,len(df)):\n",
    "    \n",
    "    for cer in certis[df['Job Title'][ind]].split(\",\"):\n",
    "        certitext = ''\n",
    "        \n",
    "        if(re.search(cer.lstrip().rstrip(),df['Full Description'][ind])):\n",
    "            certitext = cer+ \" \"+certitext \n",
    "        \n",
    "    if(certitext==''):\n",
    "            certitext= 'No Value'\n",
    "        \n",
    "    certifications.append(certitext)\n",
    "    \n",
    "    \n",
    "educ = []\n",
    "educate = pd.read_csv('EducationWords.csv')\n",
    "#educate = pd.read_csv('/content/drive/MyDrive/data/EducationWords.csv') \n",
    "for i in educate['Education']:\n",
    "    educ.append(i)\n",
    "\n",
    "def get_education(x):\n",
    "    educa =\"\"\n",
    "    education = []\n",
    "    for ed in educ:\n",
    "        if(re.search(ed.lower(),x.lower())):\n",
    "            educa = ed+\" \"+educa\n",
    "            education.append(educa)\n",
    "            \n",
    "    if len(education)!=0:\n",
    "        return (education[-1])\n",
    "    else:\n",
    "        return 'No Value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Full Description'] = df['Full Description'].astype(pd.StringDtype())\n",
    "preprocess(df,'Full Description')\n",
    "df['Full Description'] = df['Full Description'].apply(split_)\n",
    "df['Experience in years'] = df['Full Description'].apply(get_experience)\n",
    "df['Experience in years'] = df['Experience in years'].map(lambda x : x.split(' ')[0])\n",
    "df['bow'] = df['Full Description'].apply(extract_ngrams)\n",
    "df['Foreign Language'] = df['Full Description'].apply(get_language)\n",
    "df['Responsibilities'] = df['Full Description'].apply(get_responsibility)\n",
    "df['Skills'] = df['Full Description'].apply(get_skills)\n",
    "df['Certification'] = certifications\n",
    "df = df.replace(' ','No Value')\n",
    "df['Education'] = df['Full Description'].apply(get_education)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
