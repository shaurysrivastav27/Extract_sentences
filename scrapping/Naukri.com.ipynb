{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"Naukri.com_v3.0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"cells":[{"cell_type":"code","metadata":{"id":"CL-IB0kwuG8t"},"source":["from google.colab import output\n","\n","output.clear()"],"id":"CL-IB0kwuG8t","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L2SYTWIDBgdC"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","output.clear()"],"id":"L2SYTWIDBgdC","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEzzxyP-B-O-"},"source":["!apt install chromium-chromedriver\n","output.clear()"],"id":"QEzzxyP-B-O-","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ty6GRepiBhc5"},"source":["# For Selenium n Google Colab\n","!pip install selenium\n","!apt-get update \n","!pip install webdriver-manager\n","output.clear()"],"id":"ty6GRepiBhc5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9a74b90a"},"source":["from webdriver_manager.firefox import DriverManager\n","from selenium.common.exceptions import ElementClickInterceptedException\n","from selenium.common.exceptions import NoSuchElementException\n","output.clear()"],"id":"9a74b90a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xu2osfi1YoSo"},"source":["!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","output.clear()"],"id":"Xu2osfi1YoSo","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"psQTjvJMYe0-"},"source":["import sys\n","sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n","output.clear()"],"id":"psQTjvJMYe0-","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSIETMLKXgYV"},"source":["import pandas as pd\n","import time\n","import os\n","import io\n","import numpy as np\n","import requests\n","from datetime import datetime \n","import csv\n","import re\n","from bs4 import BeautifulSoup\n","output.clear()"],"id":"ZSIETMLKXgYV","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fc2d470e"},"source":["url = 'https://www.naukri.com/{name}-jobs{num}?k={name}'\n","def get_url(x,pagenum):\n","    y = x.split()\n","    return url.format(name = \"-\".join(y),num=pagenum)\n","output.clear()"],"id":"fc2d470e","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xqwJ2cMOY0Gh"},"source":["The files below should be in the same folder as the code for importing the semantics and education file."],"id":"xqwJ2cMOY0Gh"},{"cell_type":"code","metadata":{"id":"51eb8b44"},"source":["df = pd.read_excel('/content/drive/MyDrive/Semantic Titles.xlsx',sheet_name='Sheet1')\n","df.fillna('missing',inplace=True)\n","df['scrapenum'] = 0\n","for i in range(0,len(df)):\n","    #print('\\n')\n","    if((i>0) and (df['scrapenum'][i-1]==0) and (cnt>0)):\n","        df['scrapenum'][i-1]=cnt-1\n","    cnt = 0 \n","    for j in df.columns:\n","        #print(df[j][i])\n","        if(df[j][i]=='missing'):\n","            df['scrapenum'][i] = cnt-1\n","            break\n","        cnt = cnt+1\n","output.clear()"],"id":"51eb8b44","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b9GUJKvjxYkN"},"source":["certis = {}\n","for i in df['Job Title']:\n","  certis[i] = \"\""],"id":"b9GUJKvjxYkN","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9c1bzk6bpez1"},"source":["cert = pd.read_csv('/content/drive/MyDrive/data/certificates.csv') \n","for i in range(0,len(cert)):\n","  certis[cert['Job'][i].rstrip().lstrip()] = cert['Certificates'][i]"],"id":"9c1bzk6bpez1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aj0D1-0ZKamM"},"source":["from selenium import webdriver\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","driver =webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n","driver1 = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n","output.clear()"],"id":"aj0D1-0ZKamM","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkjjAxjs25XU"},"source":["def repl(x):\n","  return x.replace(\"\\t\",\"\").replace(\"\\n\",\"\").rstrip().lstrip().replace(\"  \",\" \")"],"id":"qkjjAxjs25XU","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dr4vXGDpj_sB"},"source":["dfs = pd.DataFrame()\n","fincnt = 1\n","for ind in range(0,len(df)):\n","    if(df['scrapenum'][ind]<=1):\n","        counter = 50\n","    else:\n","        counter = 50//df['scrapenum'][ind]\n","    if(counter==1):\n","      counter+=1\n","    experience,name,skills,desc,location,salary,education,links,semantics,certifications=[],[],[],[],[],[],[],[],[],[]\n","    if(df['Job Title'][0]==df['Semantic Words'][0]):\n","        applist = df.drop(['Semantic Words','scrapenum'],axis=1).columns\n","    else:\n","        applist = df.drop('scrapenum',axis=1).columns\n","    fincnt+=1\n","    if(counter<=20):\n","      print(\"----------------# \",df['Job Title'][ind],\"Page (1)------------\")\n","    for col in applist:\n","        if(df[col][ind]=='missing'):\n","            break\n","        else:\n","            if(counter<=20):  \n","                driver.get(get_url(df[col][ind],\"\"))\n","                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","                time.sleep(3)\n","                c = []\n","                count = 0\n","                for i in driver.find_elements_by_xpath(\"//div['list']//article['mb-8']\"):\n","                    if(count==counter):\n","                        break\n","                    count+=1\n","                    try:\n","                      t = i.find_element_by_css_selector('a')\n","                      links.append(t.get_attribute('href'))\n","                    except:\n","                      links.append('None')\n","                      desc.append('None')\n","                      education.append('None')\n","                      #print('link error')\n","                    if(links[len(links)-1]!='None'):\n","                      time.sleep(3)\n","                      driver1.get(t.get_attribute('href'))\n","                      desctext,eductext = \"\",\"\"\n","                      try:\n","                        desctext = driver1.find_element_by_class_name(\"dang-inner-html\").text\n","                      except NoSuchElementException:\n","                        desctext = \"None\"\n","                      try:\n","                        eductext = driver1.find_element_by_class_name(\"education\").text\n","                      except NoSuchElementException: \n","                        eductext =  \"None\"\n","                      certitext = \"\"\n","                      for cer in certis[df['Job Title'][ind]].split(\",\"):\n","                          if(re.search(cer.lstrip().rstrip(),desctext)):\n","                            certitext = cer+ \" \"+certitext \n","                      if(certitext==''):\n","                        certitext= 'None'\n","                      certifications.append(certitext)\n","                      desc.append(desctext)\n","                      education.append(eductext)\n","                            \n","                        \n","                    try:\n","                        k = i.find_elements_by_css_selector('span.ellipsis')\n","                        cntr = 0\n","                        for ki in k:\n","                            if(cntr==0):\n","                                experience.append(ki.text)\n","                            elif(cntr==1):\n","                                salary.append(ki.text)\n","                            else:\n","                                location.append(ki.text)\n","                            cntr+=1\n","                            #print(ki.text)\n","                    except NoSuchElementException:\n","                        experience.append('None')\n","                        salary.append('None')\n","                        location.append('None')\n","                        #print('error in span.ellipsis')\n","                    try:\n","                        semantics.append(df[col][ind])\n","                        name.append(i.find_element_by_css_selector('div.mt-7').find_element_by_css_selector('a').text)\n","                    except NoSuchElementException:\n","                        name.append('None')\n","                    try:\n","                        c.append(i.find_element_by_css_selector('ul.has-description').text)\n","                    except NoSuchElementException:\n","                        c.append('None')\n","                for i in c:\n","                    s = i.replace(\" \",'-')\n","                    s = s.replace(\"\\n\",\" \")\n","                    skills.append(s)\n","            else:\n","                f = True\n","                cnt1 = 0\n","                while(f):\n","                    print(\"----------------# \",df['Job Title'][ind],\"Page (\",cnt1+1,\")------------\")\n","                    if(cnt1==0):\n","                        driver.get(get_url(df[col][ind],\"\"))\n","                    else:\n","                        driver.get(get_url(df[col][ind],\"-\"+str(cnt1+1)))\n","                    cnt1=cnt1+1\n","                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","                    time.sleep(3)\n","                    c = []\n","                    for i in driver.find_elements_by_xpath(\"//div['list']//article['mb-8']\"):\n","                        try:\n","                            t = i.find_element_by_css_selector('a')\n","                            links.append(t.get_attribute('href'))\n","                        except:\n","                            links.append('None')\n","                            desc.append('None')\n","                            education.append('None')\n","                        if(links[len(links)-1]!='None'):\n","                          driver1.get(t.get_attribute('href'))\n","                          time.sleep(3)\n","                          desctext,eductext = \"\",\"\"\n","                          try:\n","                            desctext = driver1.find_element_by_class_name(\"dang-inner-html\").text\n","                          except NoSuchElementException:\n","                            desctext = \"None\"\n","                          try:\n","                            eductext = driver1.find_element_by_class_name(\"education\").text\n","                          except NoSuchElementException: \n","                            eductext =  \"None\"\n","                          certitext = \"\"\n","                          for cer in certis[df['Job Title'][ind]].split(\",\"):\n","                              if(re.search(cer.lstrip().rstrip(),desctext)):\n","                                certitext = cer+ \" \"+certitext \n","                          if(certitext==''):\n","                            certitext= 'None'\n","                          certifications.append(certitext)\n","                          desc.append(desctext)\n","                          education.append(eductext)\n","                          \n","                        try:\n","                            k = i.find_elements_by_css_selector('span.ellipsis')\n","                            cntr = 0\n","                            for ki in k:\n","                                if(cntr==0):\n","                                    experience.append(ki.text)\n","                                elif(cntr==1):\n","                                    salary.append(ki.text)\n","                                else:\n","                                    location.append(ki.text)\n","                                cntr+=1\n","                        except NoSuchElementException:\n","                            experience.append('None')\n","                            salary.append('None')\n","                            location.append('None')\n","\n","                        try:\n","                            semantics.append(df[col][ind])\n","                            name.append(i.find_element_by_css_selector('div.mt-7').find_element_by_css_selector('a').text)\n","                        except NoSuchElementException:\n","                            name.append('None')\n","                        try:\n","                            c.append(i.find_element_by_css_selector('ul.has-description').text)\n","                        except NoSuchElementException:\n","                            c.append('None')\n","      \n","                    for i in c: #loop for extracting the skills without special characters\n","                        s = i.replace(\" \",'-')\n","                        s = s.replace(\"\\n\",\" \")\n","                        skills.append(s)\n","                    if(cnt1==3):\n","                        f = False\n","    classjob = []\n","    for i in range(0,len(name)):\n","      classjob.append(df['Job Title'][ind])\n","    response = []\n","    for d in desc:\n","      f = True\n","      for res in ['responsibility','funcion','activities','activity','responsibilities','responsible']:\n","        if(re.search(res,d)):\n","          response.append(d[re.search(res,d.lower()).span()[0]:len(d)])\n","          f =False\n","          break\n","      if(f):\n","        response.append('None')\n","    if((len(semantics)==len(skills)) and (len(semantics)==len(name)) and\n","       (len(semantics)==len(desc)) and (len(semantics)==len(location)) and \n","       (len(semantics)==len(response)) and (len(semantics)==len(education))\n","       and (len(semantics)==len(salary)) and (len(semantics)==len(experience)) and len(semantics)==len(links)):\n","      dftemp = pd.DataFrame({\"Main Job Title\":semantics,\n","                            \"Searched Job Title\":classjob,\n","                           \"Company Name\":name,\n","                           \"skills\":skills,\n","                           \"description\":desc,\n","                           \"location\":location,\n","                           \"responsibilty/activity\":response,\n","                           \"education\":education,\n","                           \"Experience\":experience,\n","                           \"Certifications\": certifications,\n","                           \"salary\":salary,\n","                           \"links\":links})\n","      dfs = pd.concat([dfs,dftemp])\n","      #dftemp.to_csv('/content/drive/MyDrive/data/naukri/{}.csv'.format(df['Job Title'][ind]))\n","dfs.reset_index(drop=True)\n","dfs['skills'] = dfs['skills'].map(repl)\n","dfs['description'] = dfs['description'].map(repl) \n","dfs.to_csv('/content/drive/MyDrive/data/naukri/{}.csv'.format('naukri'))"],"id":"dr4vXGDpj_sB","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"28U-Jqw4VQLb"},"source":[""],"id":"28U-Jqw4VQLb","execution_count":null,"outputs":[]}]}